# 软件环境 
- ubuntu18.10
- python3.6
- mongodb3.6
- scrapy 1.5.1

# 创建工程
- 此项目是以apkpure.com为参照，以google play作为主站，基于scrapy框架来实现对匹配openthos系统的android应用信息抓取，因此在使用scrapy来创建项目时，基于的网址是https://play.google.com/store/apps,
过程如下：
   - scrapy startproject apkinfo
   - cd apkinfo/
   - scrapy genspider google https://play.google.com/
   
# 创建完工程，目录树如下：
![blockchain](https://img-blog.csdnimg.cn/20181219161507234.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L21keDIwMDcyNDE5,size_16,color_FFFFFF,t_70)


- 在spiders文件夹下编写自己的爬虫 
- 在items中编写容器用于存放爬取到的数据
- 在pipelines中对数据进行各种操作
- 在settings中进行项目的各种设置。


# 爬虫定义
- 修改spiders文件夹下的goole.py ，内容修改为：
  ```
      class GoogleSpider(scrapy.Spider):
         name = 'google'
         allowed_domains = ['https://play.google.com/']
         start_urls = ['https://play.google.com/store/apps/']
  ```
- 其中：  
   -  name : 爬虫的唯一标识符
   -   allowed_domains: 爬虫域名
   -   start_urls : 初始爬取的url列表
   
   
# 重写parse()函数
- 在google.py文件中存在parse()函数，是需要我们重写的函数 ， 每个初始url访问后生成的Response对象作为唯一参数传给该方法，该方法解析返回的Response，提取数据，生成item，同时生成进一步要处理的url的request对象。这个函数在后续再详细介绍。

# 修改items.py文件，添加要保存的应用程序的具体信息
```
 class ApkinfoItem(scrapy.Item):
     # define the fields for your item here like:
     # name = scrapy.Field()
     apk_name = scrapy.Field()
     apk_star = scrapy.Field()
     apk_downurl = scrapy.Field()
     apk_icon = scrapy.Field()
     apk_review = scrapy.Field()
     apk_movie = scrapy.Field()
```
# 编写google.py(spider)
- 解析https://play.google.com/store/apps 页面，得到“查看更多”（see more）的地址

```
 def parse(self, response):
         selector = scrapy.Selector(response)
         
         #获得See more 地址
         urls = selector.xpath('//a[@class="LkLjZd ScJHi U8Ww7d xjAeve nMZKrb  id-track-click "]/@href').extract()

 
         link_flag=0
 
         #yield Request要求传递的是list
         links = []
         for link in urls:
                 links.append(link)
         
         for each in urls:
             yield Request(links[link_flag], callback=self.parse_next,dont_filter=True)
             link_flag += 1                                                                     
```
